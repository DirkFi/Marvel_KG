{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推荐系统-基于word2vec \n",
    "### 数据来源：wikipedia （下载地址https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先对下载下来的压缩文件进行处理——使用gensim。处理代码详见wiki_process.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wiki_process.py zhwiki-latest-pages-articles.xml.bz2 zhwiki.txt\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初步处理后使用Opencc将文本中的繁体转为简体。处理代码详见wiki_t2s.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wiki_t2s.py –input zhwiki.txt –output zhwiki_simplified.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用iconv清洗非utf-8字符，得到wiki_final.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!iconv -c -t UTF-8 < zhwiki_simplified.txt > wiki_final.txt.utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.中文分词\n",
    "对于分词，我们选用2020年中文分词SOTA模型，论文链接：\n",
    "文件中\n",
    "\n",
    "WMSeg.ZEN.PKU.v1.1.pt为在PKU分词数据集上预训练的encoder并使用我们爬取的数据进一步训练后的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#见WMseg folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词后得到result.txt（文件夹中已包含我们分词后的txt文件）\n",
    "\n",
    "使用NLP“神器”进行word2vec训练，处理代码详见train_word2vec_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_word2vec_model.py  wiki_final.txt.utf-8 wiki.zh.text.model wiki.zh.text.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练完后会得到四个文件：\n",
    "\n",
    "wiki.zh.text.model\n",
    "\n",
    "wiki.zh.text.model.trainables.syn1neg.npy\n",
    "\n",
    "wiki.zh.text.model.wv.vectors.npy\n",
    "\n",
    "wiki.zh.text.vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练好的中文维基百科word2vec模型，可以测试一下效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('汪达', 0.7663003206253052),\n",
       " ('水行侠', 0.5412123203277588),\n",
       " ('夜魔侠', 0.5395307540893555),\n",
       " ('猛毒', 0.5015496015548706),\n",
       " ('复仇者', 0.49651220440864563),\n",
       " ('绿箭侠', 0.49295806884765625),\n",
       " ('蜘蛛人', 0.49038776755332947),\n",
       " ('曼达洛人', 0.4902873635292053),\n",
       " ('黑寡妇', 0.48650938272476196),\n",
       " ('漫威', 0.4856894612312317)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec.load(\"wiki.zh.text.model\") \n",
    "model.wv.most_similar(\"幻视\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
